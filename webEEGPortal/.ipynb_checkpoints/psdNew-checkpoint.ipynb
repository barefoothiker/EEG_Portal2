{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4105,
     "status": "ok",
     "timestamp": 1590074639515,
     "user": {
      "displayName": "Divyam Sikroria",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiVRZWqzq4HWvrKDhCE2tcsp1aMveQI5BGEW04Fw=s64",
      "userId": "07835347960014689588"
     },
     "user_tz": 240
    },
    "id": "bZSr9za0G1Ar",
    "outputId": "85f62532-4f14-4f25-ba3d-af0c72fd1828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyedflib\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/3a/63b316df182020c9fe7eab81a91c131a96df53101a3617b57e1a70445a12/pyEDFlib-0.1.17.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /home/siddhartha/anaconda3/lib/python3.6/site-packages (from pyedflib)\n",
      "Building wheels for collected packages: pyedflib\n",
      "  Running setup.py bdist_wheel for pyedflib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/siddhartha/.cache/pip/wheels/f8/f2/6b/ce6178c882779963f57d9764c3856b7cb63dd9995579be6b23\n",
      "Successfully built pyedflib\n",
      "Installing collected packages: pyedflib\n",
      "Successfully installed pyedflib-0.1.17\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyedflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4060,
     "status": "ok",
     "timestamp": 1590074639521,
     "user": {
      "displayName": "Divyam Sikroria",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiVRZWqzq4HWvrKDhCE2tcsp1aMveQI5BGEW04Fw=s64",
      "userId": "07835347960014689588"
     },
     "user_tz": 240
    },
    "id": "4mrexHphZwXo",
    "outputId": "cbca4bb7-727e-46e4-f437-0b2e9e0e6cfc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-61d6ec912503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import google.colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LW_DpHzkI42Q"
   },
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "from scipy import *\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "import scipy\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy import fftpack, linalg\n",
    "SELECTED_CHANNELS = ['F7','T5', 'F3','P3', 'F4','P4', 'F8','T6', 'Fp1','O1', 'Fp2','O2']\n",
    "import numpy as np\n",
    "import os, sys, traceback\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Hb-yvq6jIh1I"
   },
   "outputs": [],
   "source": [
    "def tridisolve(d, e, b, overwrite_b=True):\n",
    "    \"\"\"Symmetric tridiagonal system solver, from Golub and Van Loan pg 157.\n",
    "\n",
    "    Note: Copied from NiTime\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    d : ndarray\n",
    "      main diagonal stored in d[:]\n",
    "    e : ndarray\n",
    "      superdiagonal stored in e[:-1]\n",
    "    b : ndarray\n",
    "      RHS vector\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    x : ndarray\n",
    "      Solution to Ax = b (if overwrite_b is False). Otherwise solution is\n",
    "      stored in previous RHS vector b\n",
    "\n",
    "    \"\"\"\n",
    "    N = len(b)\n",
    "    # work vectors\n",
    "    dw = d.copy()\n",
    "    ew = e.copy()\n",
    "    if overwrite_b:\n",
    "        x = b\n",
    "    else:\n",
    "        x = b.copy()\n",
    "    for k in range(1, N):\n",
    "        # e^(k-1) = e(k-1) / d(k-1)\n",
    "        # d(k) = d(k) - e^(k-1)e(k-1) / d(k-1)\n",
    "        t = ew[k - 1]\n",
    "        ew[k - 1] = t / dw[k - 1]\n",
    "        dw[k] = dw[k] - t * ew[k - 1]\n",
    "    for k in range(1, N):\n",
    "        x[k] = x[k] - ew[k - 1] * x[k - 1]\n",
    "    x[N - 1] = x[N - 1] / dw[N - 1]\n",
    "    for k in range(N - 2, -1, -1):\n",
    "        x[k] = x[k] / dw[k] - ew[k] * x[k + 1]\n",
    "\n",
    "    if not overwrite_b:\n",
    "        return x\n",
    "\n",
    "\n",
    "def tridi_inverse_iteration(d, e, w, x0=None, rtol=1e-8):\n",
    "    \"\"\"Perform an inverse iteration.\n",
    "\n",
    "    This will find the eigenvector corresponding to the given eigenvalue\n",
    "    in a symmetric tridiagonal system.\n",
    "\n",
    "    Note: Copied from NiTime\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    d : ndarray\n",
    "      main diagonal of the tridiagonal system\n",
    "    e : ndarray\n",
    "      offdiagonal stored in e[:-1]\n",
    "    w : float\n",
    "      eigenvalue of the eigenvector\n",
    "    x0 : ndarray\n",
    "      initial point to start the iteration\n",
    "    rtol : float\n",
    "      tolerance for the norm of the difference of iterates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    e: ndarray\n",
    "      The converged eigenvector\n",
    "\n",
    "    \"\"\"\n",
    "    eig_diag = d - w\n",
    "    if x0 is None:\n",
    "        x0 = np.random.randn(len(d))\n",
    "    x_prev = np.zeros_like(x0)\n",
    "    norm_x = np.linalg.norm(x0)\n",
    "    # the eigenvector is unique up to sign change, so iterate\n",
    "    # until || |x^(n)| - |x^(n-1)| ||^2 < rtol\n",
    "    x0 /= norm_x\n",
    "    while np.linalg.norm(np.abs(x0) - np.abs(x_prev)) > rtol:\n",
    "        x_prev = x0.copy()\n",
    "        tridisolve(eig_diag, e, x0)\n",
    "        norm_x = np.linalg.norm(x0)\n",
    "        x0 /= norm_x\n",
    "    return x0\n",
    "\n",
    "\n",
    "def dpss_windows(N, half_nbw, Kmax, low_bias=True, interp_from=None,\n",
    "                 interp_kind='linear'):\n",
    "    \"\"\"Compute Discrete Prolate Spheroidal Sequences.\n",
    "\n",
    "    Will give of orders [0,Kmax-1] for a given frequency-spacing multiple\n",
    "    NW and sequence length N.\n",
    "\n",
    "    Note: Copied from NiTime\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        Sequence length\n",
    "    half_nbw : float, unitless\n",
    "        Standardized half bandwidth corresponding to 2 * half_bw = BW*f0\n",
    "        = BW*N/dt but with dt taken as 1\n",
    "    Kmax : int\n",
    "        Number of DPSS windows to return is Kmax (orders 0 through Kmax-1)\n",
    "    low_bias : Bool\n",
    "        Keep only tapers with eigenvalues > 0.9\n",
    "    interp_from : int (optional)\n",
    "        The dpss can be calculated using interpolation from a set of dpss\n",
    "        with the same NW and Kmax, but shorter N. This is the length of this\n",
    "        shorter set of dpss windows.\n",
    "    interp_kind : str (optional)\n",
    "        This input variable is passed to scipy.interpolate.interp1d and\n",
    "        specifies the kind of interpolation as a string ('linear', 'nearest',\n",
    "        'zero', 'slinear', 'quadratic, 'cubic') or as an integer specifying the\n",
    "        order of the spline interpolator to use.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    v, e : tuple,\n",
    "        v is an array of DPSS windows shaped (Kmax, N)\n",
    "        e are the eigenvalues\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Tridiagonal form of DPSS calculation from:\n",
    "\n",
    "    Slepian, D. Prolate spheroidal wave functions, Fourier analysis, and\n",
    "    uncertainty V: The discrete case. Bell System Technical Journal,\n",
    "    Volume 57 (1978), 1371430\n",
    "    \"\"\"\n",
    "    from scipy import interpolate\n",
    "    Kmax = int(Kmax)\n",
    "    W = float(half_nbw) / N\n",
    "    nidx = np.arange(N, dtype='d')\n",
    "\n",
    "    # In this case, we create the dpss windows of the smaller size\n",
    "    # (interp_from) and then interpolate to the larger size (N)\n",
    "    if interp_from is not None:\n",
    "        if interp_from > N:\n",
    "            e_s = 'In dpss_windows, interp_from is: %s ' % interp_from\n",
    "            e_s += 'and N is: %s. ' % N\n",
    "            e_s += 'Please enter interp_from smaller than N.'\n",
    "            raise ValueError(e_s)\n",
    "        dpss = []\n",
    "        d, e = dpss_windows(interp_from, half_nbw, Kmax, low_bias=False)\n",
    "        for this_d in d:\n",
    "            x = np.arange(this_d.shape[-1])\n",
    "            I = interpolate.interp1d(x, this_d, kind=interp_kind)\n",
    "            d_temp = I(np.linspace(0, this_d.shape[-1] - 1, N, endpoint=False))\n",
    "\n",
    "            # Rescale:\n",
    "            d_temp = d_temp / np.sqrt(sum_squared(d_temp))\n",
    "\n",
    "            dpss.append(d_temp)\n",
    "\n",
    "        dpss = np.array(dpss)\n",
    "\n",
    "    else:\n",
    "        # here we want to set up an optimization problem to find a sequence\n",
    "        # whose energy is maximally concentrated within band [-W,W].\n",
    "        # Thus, the measure lambda(T,W) is the ratio between the energy within\n",
    "        # that band, and the total energy. This leads to the eigen-system\n",
    "        # (A - (l1)I)v = 0, where the eigenvector corresponding to the largest\n",
    "        # eigenvalue is the sequence with maximally concentrated energy. The\n",
    "        # collection of eigenvectors of this system are called Slepian\n",
    "        # sequences, or discrete prolate spheroidal sequences (DPSS). Only the\n",
    "        # first K, K = 2NW/dt orders of DPSS will exhibit good spectral\n",
    "        # concentration\n",
    "        # [see http://en.wikipedia.org/wiki/Spectral_concentration_problem]\n",
    "\n",
    "        # Here I set up an alternative symmetric tri-diagonal eigenvalue\n",
    "        # problem such that\n",
    "        # (B - (l2)I)v = 0, and v are our DPSS (but eigenvalues l2 != l1)\n",
    "        # the main diagonal = ([N-1-2*t]/2)**2 cos(2PIW), t=[0,1,2,...,N-1]\n",
    "        # and the first off-diagonal = t(N-t)/2, t=[1,2,...,N-1]\n",
    "        # [see Percival and Walden, 1993]\n",
    "        diagonal = ((N - 1 - 2 * nidx) / 2.) ** 2 * np.cos(2 * np.pi * W)\n",
    "        off_diag = np.zeros_like(nidx)\n",
    "        off_diag[:-1] = nidx[1:] * (N - nidx[1:]) / 2.\n",
    "        # put the diagonals in LAPACK \"packed\" storage\n",
    "        ab = np.zeros((2, N), 'd')\n",
    "        ab[1] = diagonal\n",
    "        ab[0, 1:] = off_diag[:-1]\n",
    "        # only calculate the highest Kmax eigenvalues\n",
    "        w = linalg.eigvals_banded(ab, select='i',\n",
    "                                  select_range=(N - Kmax, N - 1))\n",
    "        w = w[::-1]\n",
    "\n",
    "        # find the corresponding eigenvectors via inverse iteration\n",
    "        t = np.linspace(0, np.pi, N)\n",
    "        dpss = np.zeros((Kmax, N), 'd')\n",
    "        for k in range(Kmax):\n",
    "            dpss[k] = tridi_inverse_iteration(diagonal, off_diag, w[k],\n",
    "                                              x0=np.sin((k + 1) * t))\n",
    "\n",
    "    # By convention (Percival and Walden, 1993 pg 379)\n",
    "    # * symmetric tapers (k=0,2,4,...) should have a positive average.\n",
    "    # * antisymmetric tapers should begin with a positive lobe\n",
    "    fix_symmetric = (dpss[0::2].sum(axis=1) < 0)\n",
    "    for i, f in enumerate(fix_symmetric):\n",
    "        if f:\n",
    "            dpss[2 * i] *= -1\n",
    "    # rather than test the sign of one point, test the sign of the\n",
    "    # linear slope up to the first (largest) peak\n",
    "    pk = np.argmax(np.abs(dpss[1::2, :N // 2]), axis=1)\n",
    "    for i, p in enumerate(pk):\n",
    "        if np.sum(dpss[2 * i + 1, :p]) < 0:\n",
    "            dpss[2 * i + 1] *= -1\n",
    "\n",
    "    # Now find the eigenvalues of the original spectral concentration problem\n",
    "    # Use the autocorr sequence technique from Percival and Walden, 1993 pg 390\n",
    "\n",
    "    # compute autocorr using FFT (same as nitime.utils.autocorr(dpss) * N)\n",
    "    rxx_size = 2 * N - 1\n",
    "    n_fft = 2 ** int(np.ceil(np.log2(rxx_size)))\n",
    "    dpss_fft = fftpack.fft(dpss, n_fft)\n",
    "    dpss_rxx = np.real(fftpack.ifft(dpss_fft * dpss_fft.conj()))\n",
    "    dpss_rxx = dpss_rxx[:, :N]\n",
    "\n",
    "    r = 4 * W * np.sinc(2 * W * nidx)\n",
    "    r[0] = 2 * W\n",
    "    eigvals = np.dot(dpss_rxx, r)\n",
    "\n",
    "    if low_bias:\n",
    "        idx = (eigvals > 0.9)\n",
    "        if not idx.any():\n",
    "            warn('Could not properly use low_bias, keeping lowest-bias taper')\n",
    "            idx = [np.argmax(eigvals)]\n",
    "        dpss, eigvals = dpss[idx], eigvals[idx]\n",
    "    assert len(dpss) > 0  # should never happen\n",
    "    assert dpss.shape[1] == N  # old nitime bug\n",
    "    return dpss, eigvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bXp_3vpcIgsK"
   },
   "outputs": [],
   "source": [
    "def getGridIndices(lowerFrequency, upperFrequency, paddedNumDataPoints, samplingFrequency):\n",
    "\n",
    "  try:\n",
    "\n",
    "      frequencyResolution = float ( samplingFrequency ) / float ( paddedNumDataPoints )\n",
    "      \n",
    "      gridValues = np.arange ( 0, samplingFrequency , frequencyResolution )\n",
    "      \n",
    "      gridValues = gridValues[ :paddedNumDataPoints ]\n",
    "\n",
    "      gridIndices = [index for index, x in enumerate (gridValues) if x>= lowerFrequency and x<= upperFrequency ]\n",
    "\n",
    "      gridValues = [x for index, x in enumerate (gridValues) if x>= lowerFrequency and x<= upperFrequency ]\n",
    "\n",
    "  except:\n",
    "    traceback.print_exc(file=sys.stdout)\n",
    "\n",
    "  return gridValues , gridIndices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3mscqWVdJVyl"
   },
   "outputs": [],
   "source": [
    "def analyzeData(datafileDirectory , fileName, numChannels, beginWin, endWin, sampingFrequency, upperFrequency, lowerFrequency, timeBandWidth, timeWindow, STEP_SIZE, numTapers):\n",
    "    try:\n",
    "        print ( \" in analyze data \")\n",
    "        \n",
    "        layFileName = fileName[:fileName.index(\".edf\")] + \".lay\"\n",
    "        dataFileName = datafileDirectory + fileName\n",
    "        channelMap1, commentsObjList1 = parseLayFile(datafileDirectory + layFileName )\n",
    "        \n",
    "        data = loadmat(datafileDirectory + \"indata/edfData_257802.mat\")[\"eegData\"]\n",
    "\n",
    "#         filePath = \"/Users/smitra/self/andre/MIT-concussion/257802-post_season_20161206_142914.edf\"\n",
    "        #f = pyedflib.EdfReader(dataFileName)\n",
    "        #signal_labels = f.getSignalLabels()\n",
    "        #numChannels = f.signals_in_file\n",
    "\n",
    "        data = data - data.mean(axis=1, keepdims=True)\n",
    "        #numChannels = 16\n",
    "\n",
    "        #beginWin = 0\n",
    "        #endWin = 0\n",
    "\n",
    "        samplingFrequency = eegFS = 250\n",
    "        #upperFrequency = 100\n",
    "        #lowerFrequency = 0\n",
    "        #timeBandWidth = 4\n",
    "        #timeWindow = 3 # time window in seconds\n",
    "        #STEP_SIZE = 2 # in seconds\n",
    "\n",
    "        numDataPoints =  timeWindow * samplingFrequency\n",
    "        stepSize = STEP_SIZE * samplingFrequency\n",
    "        padding = pad = 0\n",
    "\n",
    "        winLen = timeWindow * eegFS  \n",
    "\n",
    "        paddedNumDataPoints = int ( pow ( 2, math.ceil ( np.log2 ( winLen ) + pad) ) )\n",
    "        print(\" paddedNumDataPoints \" + str(( np.log2 ( winLen ) )))\n",
    "        print(\" numDataPoints \" + str(( numDataPoints )))\n",
    "        print(\" timeBandWidth \" + str(( timeBandWidth )))\n",
    "\n",
    "        numTapers = 2 * timeBandWidth -1\n",
    "        print(\" numTapers \" + str(( numTapers )))\n",
    "        [tapers, eigenValues] = dpss_windows(int(numDataPoints), float(timeBandWidth), int(numTapers) )\n",
    "\n",
    "        #numTapers = len(tapers)\n",
    "        #numTapers = 6\n",
    "\n",
    "        fpass = [lowerFrequency,upperFrequency]\n",
    "\n",
    "        print (\"fpass = \" + str(fpass))\n",
    "        print ( \" padded num = \" + str(paddedNumDataPoints))\n",
    "        print (\" eeg fs \" + str(eegFS))\n",
    "        gridValues, gridIndices = getGridIndices(fpass[0], fpass[1], paddedNumDataPoints, eegFS)\n",
    "\n",
    "        print (\" grid values \" + str(len(gridValues)))\n",
    "        print (\" grid indices \" + str(len(gridIndices)))\n",
    "\n",
    "        dataMatrix = []\n",
    "\n",
    "        #spectrumChannelSumData = [0] * ( upperFrequency - lowerFrequency + 1 )\n",
    "        spectrumChannelSumData = [] \n",
    "\n",
    "        for channelIndex in range(numChannels):\n",
    "\n",
    "          spectrogramData = []\n",
    "\n",
    "          channelData = data[channelIndex]\n",
    "\n",
    "          #channelData = f.readSignal(channelIndex)\n",
    "          #channelData = channelData - channelData.mean(axis=1, keepdims=True)\n",
    "\n",
    "          #channelLabel = signal_labels[channelIndex]\n",
    "\n",
    "          # only process selected channels\n",
    "          if channelIndex != 13:\n",
    "            continue\n",
    "          #print (\"for channel \" + channelLabel)\n",
    "\n",
    "          print (str(len(  channelData )))\n",
    "          numWindows = int ( ( len ( channelData ) - numDataPoints + 1) / ( stepSize  ) )\n",
    "          numWindows = math.floor ( float( len ( channelData ))/ float(numDataPoints) )\n",
    "\n",
    "          #print ( \" numWindows = \" + str(numWindows) )\n",
    "\n",
    "          #theta (4-7 Hz), alpha (9-13 Hz), beta (15-25 Hz) and gamma (30-50 Hz)       \n",
    "          thetaPowerSpectra = []\n",
    "          alphaPowerSpectra = []\n",
    "          betaPowerSpectra = []\n",
    "          gammaPowerSpectra = []\n",
    "\n",
    "          for windowNum in range ( numWindows ) :\n",
    "\n",
    "              beginWin = windowNum * numDataPoints\n",
    "              endWin = beginWin + numDataPoints\n",
    "\n",
    "              print (\" window num = \" + str(windowNum) )\n",
    "\n",
    "              #print ( \" beginWin = \" + str(beginWin) + \" endWin = \" + str(endWin))\n",
    "\n",
    "              windowData = channelData [ beginWin : endWin]\n",
    "\n",
    "              #print ( \" windowData = \" + str(windowData) )\n",
    "\n",
    "              if len(windowData) == 0:\n",
    "\n",
    "                break\n",
    "\n",
    "              #if windowNum == 5:\n",
    "              #      break\n",
    "\n",
    "\n",
    "              spectrumChannelSumData = []\n",
    "              for taperIndex, taper in enumerate ( tapers ) :\n",
    "\n",
    "                taperData = [float(a)*float(b) for a,b in zip(windowData,taper)]\n",
    "\n",
    "                fftData = scipy.fftpack.fft(taperData,paddedNumDataPoints)\n",
    "\n",
    "                #print ( \" fftData before = \" + str(len(fftData)) )\n",
    "                #print ( \" paddedNumDataPoints before = \" + str(paddedNumDataPoints) )        \n",
    "\n",
    "                fftData = np.array (fftData)/float(eegFS)\n",
    "\n",
    "                fftData = fftData[gridIndices]\n",
    "                #print (fftData)\n",
    "                #break\n",
    "                #fftData = [fftData[x] for x in gridIndices]\n",
    "                #print (np.shape(windowData))\n",
    "                #print (windowData)        \n",
    "\n",
    "                #spectrumChannelData = np.array([log(abs(x*conj(x))) for x in fftData])\n",
    "                spectrumChannelData = np.array([abs(x*conj(x)) for x in fftData])\n",
    "\n",
    "                plt.figure(1, figsize = (8.5,11))\n",
    "                plt.title('Spectrogram')\n",
    "                #plt.plot(spectrumChannelData)\n",
    "\n",
    "                #print (spectrumChannelData)\n",
    "\n",
    "                #break\n",
    "\n",
    "                spectrumChannelSumData.append( list(spectrumChannelData))\n",
    "\n",
    "              #break\n",
    "              #print (spectrumChannelSumData)\n",
    "              #print ( \" shape = \" + str(np.shape(spectrumChannelSumData)))\n",
    "              spectrumChannelAvgData = [float(sum(col))/len(col) for col in zip(*spectrumChannelSumData)] \n",
    "              #spectrumChannelAvgData = [log(x) for x in spectrumChannelAvgData]\n",
    "              #spectrumChannelAvgData = np.mean( spectrumChannelSumData, axis = 0 ) \n",
    "\n",
    "              spectrogramData.append(list(spectrumChannelAvgData))\n",
    "\n",
    "              #if windowNum == 0:\n",
    "              #    plt.plot(spectrumChannelAvgData)\n",
    "              #    plt.show()\n",
    "\n",
    "          #break\n",
    "\n",
    "          spectrumPSD = [float(sum(col))/len(col) for col in zip(*spectrogramData)]\n",
    "          spectrumPSD = np.array(spectrumPSD)/100\n",
    "\n",
    "          plt.clf()\n",
    "          #plt.show()\n",
    "          plt.figure(1, figsize = (8.5,11))\n",
    "          #plt.figure()\n",
    "\n",
    "          #print([len(x) for x in spectrogramData])\n",
    "          #np.savetxt(\"outdata/py_spectrogram_data\" + str(channelIndex+1) + \".txt\", np.array(spectrogramData).transpose() )\n",
    "          #print ( \" shape = \" + str(np.shape(np.array(spectrogramData))))\n",
    "          #plt.figure(1)\n",
    "          #plt.subplot(211)\n",
    "          #plt.plot(spectrumPSD)    \n",
    "\n",
    "          #plt.subplot(212)\n",
    "          plt.figure(1, figsize = (8.5,11))\n",
    "          plt.imshow(np.array(log(spectrogramData)).transpose())\n",
    "          #plt.imshow(np.array(spectrogramData).transpose())\n",
    "\n",
    "          plt.gca().invert_yaxis()\n",
    "          plt.axis([0, 416, 0, 100])\n",
    "          plt.show()    \n",
    "          break\n",
    "    except:\n",
    "            traceback.print_exc(file=sys.stdout)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hn7502CWJiFu"
   },
   "outputs": [],
   "source": [
    "def parseLayFile(layFileName):\n",
    "\n",
    "    try:\n",
    "        \n",
    "        print (layFileName)\n",
    "\n",
    "        f = open(layFileName, \"r\")\n",
    "        \n",
    "        impedanceMapFound = False\n",
    "        chennalMapFound = False\n",
    "        patientDataFound = False\n",
    "        epochDataFound = False\n",
    "        commentsFound = False\n",
    "        startFlag = False\n",
    "        endFlag = False\n",
    "\n",
    "        commentsObjList = []\n",
    "        \n",
    "        channelMap = {}\n",
    "        patientMap = {}\n",
    "        \n",
    "        commentNum = 0\n",
    "        \n",
    "        for index, line in enumerate(f):\n",
    "          \n",
    "            line = line.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\"\\t\",\"\")\n",
    "            \n",
    "            if line.find(\"ImpedanceMap\") != -1:\n",
    "                impedanceMapFound = True\n",
    "                continue\n",
    "            \n",
    "            if line.find(\"ChannelMap\") != -1:\n",
    "                impedanceMapFound = False\n",
    "                channelMapFound = True\n",
    "                continue            \n",
    "            \n",
    "            if line.find(\"Patient\") != -1:\n",
    "                channelMapFound = False\n",
    "                patientDataFound = True\n",
    "                continue      \n",
    "             \n",
    "            if line.find(\"Comments\") != -1:\n",
    "                impedanceMapFound = False\n",
    "                patientDataFound = False\n",
    "                channelMapFound = False\n",
    "                commentsFound = True\n",
    "                continue \n",
    "              \n",
    "            if impedanceMapFound:\n",
    "                data = line.split(\"=\")\n",
    "                print (\" ####### data = \" + str(data) )\n",
    "                channelMap[data[0]] = data[1]\n",
    "                 \n",
    "            if patientDataFound:\n",
    "                data = line.split(\"=\")\n",
    "                #patientMap[data[0]] = data[1]\n",
    "                     \n",
    "            #if commentsFound:\n",
    "                #print ( str(line) ) \n",
    "                #data = line.split(\",\")\n",
    "                #print ( str(data))\n",
    "                #if line.find(\"START\") != -1:\n",
    "                    #startFlag = True\n",
    "                    #endFlag = False\n",
    "                    #commentsObj = CommentsObj()\n",
    "                    #commentsObj.startTime = data[0]\n",
    "                    #commentString = data[4]\n",
    "                    #commentsObj.description = commentString[:commentString.find(\"START\")]\n",
    "                #elif line.find(\"END\") != -1:\n",
    "                    #commentsObj.endTime = data[0]\n",
    "                    #print ( \" ########## adding ########### \")\n",
    "                    #commentsObjList.append(commentsObj)\n",
    "\n",
    "            if commentsFound:\n",
    "                \n",
    "                print ( str(line) ) \n",
    "                data = line.split(\",\")\n",
    "                print ( str(data))\n",
    "                \n",
    "                if line.find(\"loss\") == -1:\n",
    "                \n",
    "                    commentsObj = CommentsObj()\n",
    "                    commentsObj.commentNum = commentNum\n",
    "                    commentNum += 1\n",
    "                    commentsObj.startTime = data[0]\n",
    "                    commentString = data[4]\n",
    "                    commentsObj.description = commentString\n",
    "                    commentsObjList.append(commentsObj)\n",
    "                    \n",
    "        print ( \"** \" + str([ x.startTime + \":: \" + x.description  for x in commentsObjList ]) ) \n",
    "        print ( channelMap )\n",
    "        \n",
    "    except:\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "    return channelMap, commentsObjList \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9ByT45KLJwP5"
   },
   "outputs": [],
   "source": [
    "class CommentsObj(object):\n",
    "    def __init__(self):\n",
    "\n",
    "        self.commentNum = 0\n",
    "        self.startTime = ''\n",
    "        self.description = ''\n",
    "\n",
    "    def __unicode__(self):\n",
    "        return str(self.fileName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14044,
     "status": "ok",
     "timestamp": 1590074649629,
     "user": {
      "displayName": "Divyam Sikroria",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhiVRZWqzq4HWvrKDhCE2tcsp1aMveQI5BGEW04Fw=s64",
      "userId": "07835347960014689588"
     },
     "user_tz": 240
    },
    "id": "Trui9z9fJym8",
    "outputId": "a163dffc-58ef-4e49-e107-3826c446f1d9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyzeData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4a7ba9a735db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0manalyzeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/andre/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"test.edf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'analyzeData' is not defined"
     ]
    }
   ],
   "source": [
    "#datafileDirectory = \"/content/drive/My Drive/andre/\"\n",
    "#fileName = \"257802-post_season_20161206_142914.edf\"\n",
    "#fileName = \"test.edf\"\n",
    "\n",
    "\n",
    "analyzeData(\"/content/drive/My Drive/andre/\",\"test.edf\",16,0,0,250,100,0,4,3,2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-9EZv2rJUlS8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "psdNew.ipynb",
   "provenance": [
    {
     "file_id": "1X0mBdGuQjopJpLjRn_ybxA_6mCUUcZ64",
     "timestamp": 1589492055150
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
